import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from nltk.tokenize import word_tokenize
import string
import nltk
nltk.download('punkt')

# Load the database
database = pd.read_csv("Language Detection.csv")

# Preprocess the text by removing punctuation and converting to lowercase
database["Text"] = database["Text"].apply(lambda x: x.translate(str.maketrans("", "", string.punctuation)).lower())

# Split the database into training and testing sets
train_data, test_data = train_test_split(database, test_size=0.2, random_state=42)

# Initialize a TfidfVectorizer object to convert the preprocessed text into a matrix of TF-IDF features
vectorizer = TfidfVectorizer(tokenizer=word_tokenize, lowercase=True, stop_words=None, max_features=5000)

# Fit the vectorizer on the training data and transform both the training and testing data
X_train = vectorizer.fit_transform(train_data["Text"])
X_test = vectorizer.transform(test_data["Text"])

# Extract the language labels from the training and testing data
y_train = train_data["Language"]
y_test = test_data["Language"]

# Train a logistic regression classifier on the training data
clf = LogisticRegression()
clf.fit(X_train, y_train)

# Evaluate the performance of the trained classifier on the testing data
accuracy = clf.score(X_test, y_test)
print("Accuracy:", accuracy)

# Get user input
user_input = input("Enter text: ")

# Preprocess the user input
preprocessed_input = user_input.translate(str.maketrans("", "", string.punctuation)).lower()

# Vectorize the preprocessed input
X_user = vectorizer.transform([preprocessed_input])

# Use the trained classifier to predict the language of the user input
predicted_language = clf.predict(X_user)[0]

# Print the predicted language to the screen
print("The language is:", predicted_language)

